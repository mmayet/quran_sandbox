{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read quran.json\n",
    "f = open('data/nas.json', 'r', encoding=\"utf-8\")\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بِسْمِ اللَّهِ الرَّحْمَٰنِ الرَّحِيمِ قُلْ أَعُوذُ بِرَبِّ النَّاسِ\n",
      "مَلِكِ النَّاسِ\n",
      "إِلَٰهِ النَّاسِ\n",
      "مِنْ شَرِّ الْوَسْوَاسِ الْخَنَّاسِ\n",
      "الَّذِي يُوَسْوِسُ فِي صُدُورِ النَّاسِ\n",
      "مِنَ الْجِنَّةِ وَالنَّاسِ\n"
     ]
    }
   ],
   "source": [
    "for i in data['data']['ayahs']:\n",
    "    print(i['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarabic import araby\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.isri import ISRIStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes arabic vowels and stylistic spacing\n",
    "sw1 = get_stop_words('arabic') + stopwords.words(\"arabic\")\n",
    "sw2 = ['ا','أ','إ','ذ','ض','ص','ث','ق','ف','غ','ع','ه','خ','ح','ج','ش','س','ي','ب','ل','ا','ال','ت','ن','م','ك','ئ','ء','ؤ','ر','لا','ى','ة','و','ز','ظ']\n",
    "sw3 = [\"۞\",\"آله\", \"أبو\", \"أبي\", \"أثنى\", \"أحدهما\", \"أظهرهما\", \"أن\", \"أنه\", \"أو\", \"أى\", \"إلا\", \"إلخ\", \"إله\", \"إلى\", \"ابن\", \"ابو\",\"ابي\", \"الآتي\", \"الأستاذ\", \"الأولباب\", \"الامام\", \"البصير\", \"الثانية\", \"الجلال\", \"الحمد\", \"الخ\", \"الدكتور\", \"الرحمن\", \"الرحيم\", \"الرسول\", \"السميع\",\"الشارح\", \"الشيء\", \"الشيخ\", \"الصمد\", \"العبد\", \"العلامة\", \"العلي\", \"الفقير\", \"القدير\", \"الكتاب\", \"الله\", \"المؤلف\", \"المؤلفة\", \"المجلد\",\"المسألة\", \"المصنف\", \"النبي\", \"الي\", \"انتهى\", \"انظر\", \"اهـ\", \"باب\", \"بالواو\", \"بدلالة\", \"برقم\", \"بسم\", \"بعد\", \"بقيد\", \"بمثابة\", \"بن\", \"به\",\"بها\", \"بين\", \"بينهما\", \"تأمل\", \"تخريجه\", \"تعالى\", \"تعبيره\", \"ثم\", \"ثناء\", \"حتى\", \"حكاهما\", \"حمدا\", \"خصما\", \"دليلنا\", \"ذكرنا\", \"ذكرناه\", \"ر\"]\n",
    "sw4 = ['فقط','ولعل','اختلافهم','فقولان','فصلوأما','اليه','قدمنا','ثالثها','معنى','تقدم','والله','أنها','بلا','وأن','بفاس','منهم','أعلم','ففيه','وهل','أنها','وأن','ذكره','كلامه','قاله','نقله','منهما','بأنه','بنحو','ومحل','نقل','وجهين','فعلى','كون','وأن','أحد','بلا','','','','','','لقول','أنها','أخذ','ففي','ذكره','فاذا','ويدل','قيل','قالوا','القول','وجه','المعنى','وجهين','باعتبار','اعتبار','بينا','بأس','فلذلك','فلهذا','وقاله','تأويلان','القولين','بقوله','إليه','بذلك','شيئا','عنده','وذاك','لعدم','ومنهم','قولين','عبارة','زيادتي','وينبغي','ولهذا','أكان','وخبر','وحينئذ','رحمهم','فهنا','إليه','فلم','غيره','أيضا','ولسنا','جميعهم','وليسوا','الأوجه','التالية','وثالثها','قلت','وكذلك','وسلم','وقال','شيء','لأن','لأن','فهو','فقال','لأنه','رحمه','فلما','يكن','وابن','رسول','النبي','وقيل','وكذا','وإلا','ونحوه','واحد','فلو','الأول','بأن','والثاني','وجهان','قلنا','الله',\"فقال\",\"وعن\",\"ربه\", \"رحمة\", \"رسول\", \"رضى\", \"رضي\", \"رقم\", \"رها\", \"سبحانه\", \"سنن\", \"سيأتي\", \"شرح\", \"شيخ\", \"صلى\", \"طبقات\", \"عبد\", \"على\", \"عليكم\", \"عليه\", \"عن\",\"عند\", \"عنه\", \"غير\", \"فأشبه\", \"فأما\", \"فإن\", \"فإنا\", \"فإنه\", \"فائدة\", \"فافهم\", \"فالأصح\", \"فالقاضي\", \"فالوجه\", \"فان\", \"فانه\", \"فجاز\", \"فدل\", \"فصل\",\"فكان\", \"فلأن\", \"فلأنه\", \"فلا\", \"فلما\", \"فليتأمل\", \"فمنهم\", \"فنقول\", \"فهذا\", \"فهل\", \"فوجهان\", \"فى\", \"في\", \"فيه\", \"فيها\", \"قال\", \"قبل\", \"قدمناه\",\"قلنا\", \"قول\", \"قولان\", \"قوله\", \"كان\", \"كتاب\", \"كلام\", \"كلامهم\", \"كما\", \"كونه\", \"لأنا\", \"لأنه\", \"لأنها\", \"لان\", \"لانه\", \"لخبر\", \"لذلك\", \"لرحمة\",\"لقوله\", \"له\", \"لهم\", \"لو\", \"مادة\", \"مثال\", \"مثلا\", \"عبدا\", \"مع\", \"معطوف\", \"مقدمة\", \"من\", \"مناهج\", \"منتهى\", \"منه\", \"نسخة\", \"نسلم\", \"نصا\",\"نصه\", \"نقول\", \"هريرة\", \"ههنا\", \"وأصحهما\", \"وأما\", \"وأيضا\", \"وإن\", \"وإنما\", \"وإنه\", \"واحتج\", \"واعلم\", \"والتقوى\", \"والثانى\", \"والثاني\",\"والسلام\", \"والصلاة\", \"وان\", \"وانظر\", \"وبالله\", \"وبه\", \"وتقدم\", \"وجزم\", \"وجل\", \"وجهان\", \"وسلم\", \"وسن\", \"وشرعا\", \"وصلى\", \"وعبارة\", \"وعلى\",\"وعنه\", \"وغيره\", \"وغيرهم\", \"وفى\", \"وقال\", \"وقد\", \"وقدمه\", \"وقوله\", \"وقولي\", \"وقيل\", \"وكذلك\", \"ولأن\", \"ولأنه\", \"ولأنها\", \"ولذا\", \"ولكنا\", \"ولنا\", \"ولو\",\"عنهم\", \"وهذا\", \"وهنا\",'فذا','فهذ','هتحقيق','فاستخلفه','واعتبارا','وبالجملة','اليها','وذا',\"وهو\", \"ويحتمل\", \"يعني\", \"يقال\", \"يقول\", \"يكون\"]\n",
    "sw = set(sw1+sw2+sw3+sw4)\n",
    "\n",
    "#NLTK Stemmer\n",
    "st = ISRIStemmer()\n",
    "\n",
    "accents = [' ّ', ' َ', ' ً', ' ُ', ' ٌ', ' ِ', ' ٍ', ' ْ', 'ـ', 'ٖ', '‎']\n",
    "letters = ['ذ', 'ض', 'ص', 'ث', 'ق', 'ف', 'غ', 'ع', 'ه', 'خ', 'ح', 'ج', 'د', 'ش', 'س', 'ي', 'ب', 'ل', 'ا', 'ت', 'ن', 'م', 'ك', 'ط', 'ئ', 'ء', 'ؤ', 'ر', 'لا', 'ى', 'ة', 'و', 'ز', 'ظ', 'آ']\n",
    "\n",
    "# excludes stop words\n",
    "def not_sw(text):\n",
    "    return (text not in sw) or st.stem(text) not in sw\n",
    "\n",
    "#exclude single letters, combined words, and stop words\n",
    "def not_small_big(text):\n",
    "    return (len(text) >= 3) and (len(text) <= 9)\n",
    "\n",
    "def strip_text(text):\n",
    "    return araby.strip_tatweel(araby.strip_tashkeel(text))\n",
    "\n",
    "def deNoise(text):\n",
    "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                            ـ    | # Tatwil/Kashida\n",
    "                             ٰ    | # Madd\n",
    "                             ٖ    | # Madd\n",
    "                            ‎    | # Madd\n",
    "                            ‎    | # Madd\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(noise, '', text)\n",
    "    return text\n",
    "\n",
    "def clean_word_list(text):\n",
    "    cleaned_word_list = []\n",
    "    for word in text:\n",
    "        if not_sw(word) and not_small_big(word):\n",
    "            cleaned_word_list.append(strip_text(deNoise(word)))\n",
    "    return cleaned_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بسم الله الرحمن الرحيم قل أعوذ برب الناس\n",
      "ملك الناس\n",
      "إله الناس\n",
      "من شر الوسواس الخناس\n",
      "الذي يوسوس في صدور الناس\n",
      "من الجنة والناس\n"
     ]
    }
   ],
   "source": [
    "for i in data['data']['ayahs']:\n",
    "    print(deNoise(i['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
